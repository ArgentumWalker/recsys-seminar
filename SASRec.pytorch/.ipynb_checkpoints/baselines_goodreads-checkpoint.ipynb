{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from lightfm import LightFM\n",
    "import multiprocessing as mp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beauty.txt\t   Steam.txt  beer.txt\t     ml-1m.txt\n",
      "DataProcessing.py  Video.txt  goodreads.txt\n"
     ]
    }
   ],
   "source": [
    "datasets_path = '/home/worker/persistent/code/KERN/xgb_data/recsys-seminar/SASRec/data/'\n",
    "datasets_path = Path(datasets_path)\n",
    "\n",
    "!ls '/home/worker/persistent/code/KERN/xgb_data/recsys-seminar/SASRec/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset, args):\n",
    "    [train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)\n",
    "\n",
    "    NDCG = 0.0\n",
    "    HT = 0.0\n",
    "    valid_user = 0.0\n",
    "\n",
    "    if usernum>10000:\n",
    "        users = random.sample(range(1, usernum + 1), 10000)\n",
    "    else:\n",
    "        users = range(1, usernum + 1)\n",
    "    for u in users:\n",
    "\n",
    "        if len(train[u]) < 1 or len(test[u]) < 1: continue\n",
    "\n",
    "        seq = np.zeros([args.maxlen], dtype=np.int32)\n",
    "        idx = args.maxlen - 1\n",
    "        seq[idx] = valid[u][0]\n",
    "        idx -= 1\n",
    "        for i in reversed(train[u]):\n",
    "            seq[idx] = i\n",
    "            idx -= 1\n",
    "            if idx == -1: break\n",
    "        rated = set(train[u])\n",
    "        rated.add(0)\n",
    "        item_idx = [test[u][0]]\n",
    "        for _ in range(100):\n",
    "            t = np.random.randint(1, itemnum + 1)\n",
    "            while t in rated: t = np.random.randint(1, itemnum + 1)\n",
    "            item_idx.append(t)\n",
    "\n",
    "        predictions = -model.predict(*[np.array(l) for l in [[u], [seq], item_idx]])\n",
    "        predictions = predictions[0] # - for 1st argsort DESC\n",
    "\n",
    "        rank = predictions.argsort().argsort()[0].item()\n",
    "\n",
    "        valid_user += 1\n",
    "\n",
    "        if rank < 10:\n",
    "            NDCG += 1 / np.log2(rank + 2)\n",
    "            HT += 1\n",
    "        if valid_user % 100 == 0:\n",
    "            print('.', end=\"\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    return NDCG / valid_user, HT / valid_user\n",
    "\n",
    "\n",
    "# evaluate on val set\n",
    "def evaluate_valid(model, dataset, args):\n",
    "    [train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)\n",
    "\n",
    "    NDCG = 0.0\n",
    "    valid_user = 0.0\n",
    "    HT = 0.0\n",
    "    if usernum>10000:\n",
    "        users = random.sample(range(1, usernum + 1), 10000)\n",
    "    else:\n",
    "        users = range(1, usernum + 1)\n",
    "    for u in users:\n",
    "        if len(train[u]) < 1 or len(valid[u]) < 1: continue\n",
    "\n",
    "        seq = np.zeros([args.maxlen], dtype=np.int32)\n",
    "        idx = args.maxlen - 1\n",
    "        for i in reversed(train[u]):\n",
    "            seq[idx] = i\n",
    "            idx -= 1\n",
    "            if idx == -1: break\n",
    "\n",
    "        rated = set(train[u])\n",
    "        rated.add(0)\n",
    "        item_idx = [valid[u][0]]\n",
    "        for _ in range(100):\n",
    "            t = np.random.randint(1, itemnum + 1)\n",
    "            while t in rated: t = np.random.randint(1, itemnum + 1)\n",
    "            item_idx.append(t)\n",
    "\n",
    "        predictions = -model.predict(*[np.array(l) for l in [[u], [seq], item_idx]])\n",
    "        predictions = predictions[0]\n",
    "\n",
    "        rank = predictions.argsort().argsort()[0].item()\n",
    "\n",
    "        valid_user += 1\n",
    "\n",
    "        if rank < 10:\n",
    "            NDCG += 1 / np.log2(rank + 2)\n",
    "            HT += 1\n",
    "        if valid_user % 100 == 0:\n",
    "            print('.', end=\"\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    return NDCG / valid_user, HT / valid_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset goodreads.txt\n"
     ]
    }
   ],
   "source": [
    "# ratings = pd.read_csv('ml-1m/ratings.dat', delimiter='::', header=None, \n",
    "#         names=['user_id', 'movie_id', 'rating', 'timestamp'], \n",
    "#         usecols=['user_id', 'movie_id', 'rating'], engine='python')\n",
    "\n",
    "# movie_info = pd.read_csv('ml-1m/movies.dat', delimiter='::', header=None, \n",
    "#         names=['movie_id', 'name', 'category'], engine='python')\n",
    "file = 'goodreads.txt'#'Beauty.txt'#   Steam.txt  Video.txt  ml-1m.txt\n",
    "        \n",
    "print('dataset', file)\n",
    "users = []\n",
    "movies = []\n",
    "with open(datasets_path / file, 'r') as data:\n",
    "    lines = data.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        user_movie = line.split(' ')\n",
    "        user = int(user_movie[0])\n",
    "        movie = int(user_movie[1])\n",
    "\n",
    "        users.append(user)\n",
    "        movies.append(movie)\n",
    "\n",
    "df_data = {\n",
    "    'user_id': users,\n",
    "    'movie_id': movies\n",
    "}\n",
    "\n",
    "interactions = pd.DataFrame.from_dict(df_data)\n",
    "del df_data\n",
    "del lines\n",
    "ratings = interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratings = ratings.loc[(ratings['rating'] >= 4)]\n",
    "users = ratings[\"user_id\"]\n",
    "movies = ratings[\"movie_id\"]\n",
    "#user_item = sp.coo_matrix((np.ones_like(users), (users, movies)))\n",
    "#user_item_csr = user_item.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grouped\n",
      "CPU times: user 54.1 s, sys: 1.26 s, total: 55.4 s\n",
      "Wall time: 55.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "unique_users = np.unique(users)\n",
    "unique_movies = set(np.unique(movies))\n",
    "\n",
    "grouped_interactions = ratings.groupby('user_id')['movie_id'].apply(list)\n",
    "del ratings\n",
    "train_dataset = {}\n",
    "test_dataset = {}\n",
    "#negative_dataset = {}\n",
    "#all_dataset = {}\n",
    "print('grouped')\n",
    "grouped_len = len(grouped_interactions)\n",
    "counter = 0\n",
    "prcnt = 0\n",
    "\n",
    "for user_id, user_movies in grouped_interactions.iteritems():\n",
    "    if len(user_movies) < 2:\n",
    "        continue\n",
    "        \n",
    "    if counter >= grouped_len / 100:\n",
    "        counter = 0\n",
    "        prcnt += 1\n",
    "        \n",
    "        #print('percentage processed', prcnt)\n",
    "    \n",
    "    train_dataset[user_id] = user_movies[:-1]\n",
    "    test_dataset[user_id] = user_movies[-1]\n",
    "    #negative_dataset[user_id] =  list(unique_movies - set(user_movies))\n",
    "    counter += 1\n",
    "\n",
    "del grouped_interactions\n",
    "total_users = list(test_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416603, 416603)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(total_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(542145, 124082)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_users = max(users)\n",
    "max_movies = max(movies)\n",
    "\n",
    "max_users, max_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_csr_data(interactions):\n",
    "    coo_users = []\n",
    "    for user_id in interactions:\n",
    "        coo_users.append(np.full(len(interactions[user_id]), user_id))\n",
    "    \n",
    "    coo_users = np.hstack(coo_users)\n",
    "    coo_movies = []\n",
    "    for user_id in interactions:\n",
    "        coo_movies.append(np.array(interactions[user_id]))\n",
    "    \n",
    "    coo_movies = np.hstack(coo_movies)\n",
    "    \n",
    "    user_item = sp.coo_matrix((np.ones_like(coo_users), (coo_users, coo_movies)), shape=(max_users + 1, max_movies + 1))\n",
    "    return user_item.tocsr()\n",
    "\n",
    "train_data = extract_csr_data(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично статье из NCF будем сравнивать все модели по метрикам Hit rate(HR@K) и NDCG@K. K = 10\n",
    "Помимо одного позитива, также добавим 99 случайных негативных фильмов для пользователя, тем самым будем оценивать эти метрики относительно ранжирования этих 1 + 99 фильмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics_for_user(args):\n",
    "    k = 10\n",
    "    model, user_id = args\n",
    "    if user_id not in test_dataset:\n",
    "        return None\n",
    "    \n",
    "    last_user_movie = test_dataset[user_id]\n",
    "    seen_movies = train_dataset[user_id] + [last_user_movie]\n",
    "    negative_samples = list(unique_movies - set(seen_movies))\n",
    "    #print(len(negative_samples))\n",
    "    np.random.shuffle(negative_samples)\n",
    "    random_negative_movies = negative_samples[:999]\n",
    "    #print(last_user_movie)\n",
    "    input_movies = np.array([last_user_movie] + list(random_negative_movies))\n",
    "    input_user = np.full(len(input_movies), user_id)\n",
    "    #print('input_movies', input_movies)\n",
    "    pred = model.predict(input_user, input_movies)\n",
    "    #print(pred)\n",
    "    top_movies = input_movies[np.argsort(pred)[-k:]]\n",
    "    #print('top', top_movies)\n",
    "    hit_rate = 1 if last_user_movie in top_movies else 0\n",
    "\n",
    "    ndcg = 0 # TODO? 1 / np.log2(rank + 2)\n",
    "    for position, movie in enumerate(top_movies):\n",
    "        if movie == last_user_movie:\n",
    "            ndcg = 1 / np.log2(position + 2)\n",
    "            break\n",
    "    return hit_rate, ndcg\n",
    "\n",
    "def evaluate_model(model):\n",
    "    with mp.Pool(mp.cpu_count()) as pool:\n",
    "        users_len = len(total_users)\n",
    "        metrics = pool.map(evaluate_metrics_for_user, zip([model] * users_len, total_users))\n",
    "        hrs = [metric[0] for metric in metrics if metric is not None]\n",
    "        ndcgs = [metric[1] for metric in metrics if metric is not None]\n",
    "\n",
    "    print('Mean HR', np.mean(hrs))\n",
    "    print('Mean NDCG', np.mean(ndcgs))\n",
    "    \n",
    "#evaluate_metrics_for_user((baseline_warp, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 40/40 [21:33<00:00, 32.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f7d7c9fd410>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_warp = LightFM(\n",
    "    no_components=64, \n",
    "    learning_rate=0.01,\n",
    "    loss='warp',\n",
    "    max_sampled=200\n",
    ")\n",
    "\n",
    "baseline_warp.fit(train_data, epochs=40, verbose=True, num_threads=mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean HR 0.7783933385021231\n",
      "Mean NDCG 0.2474113564557018\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(baseline_warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 40/40 [04:37<00:00,  6.93s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f7e17a30fd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_bpr = LightFM(\n",
    "    no_components=64, \n",
    "    learning_rate=0.01,\n",
    "    loss='bpr',\n",
    "    max_sampled=200\n",
    ")\n",
    "\n",
    "baseline_bpr.fit(train_data, epochs=40, verbose=True, num_threads=mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean HR 0.6467284201025917\n",
      "Mean NDCG 0.20998324031703727\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(baseline_bpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    \n",
    "    def __init__(self, model, user_emb, item_emb, bias_u=None, bias_i=None):\n",
    "        self.model = model\n",
    "        self.user_emb = user_emb\n",
    "        self.user_bias = bias_u\n",
    "        self.item_emb = item_emb\n",
    "        self.item_bias = bias_i\n",
    "        \n",
    "    def predict(self, users, movies):\n",
    "        return self.model.predict(users, movies)\n",
    "    \n",
    "    def similars(self, toy_movie_id=1, top=10):\n",
    "        input_vector = self.item_emb[toy_movie_id]\n",
    "\n",
    "        data = []\n",
    "        for item_idx, column in enumerate(self.item_emb):\n",
    "            dst = np.linalg.norm(column - input_vector)\n",
    "            data.append((item_idx, dst))\n",
    "\n",
    "        sorted_by_dst = list(sorted(data, key=lambda val: val[1]))\n",
    "\n",
    "        similars = []\n",
    "        for item in sorted_by_dst:\n",
    "            search = movie_info[movie_info[\"movie_id\"] == item[0]]\n",
    "            movie_name = search[\"name\"].to_string()\n",
    "            if len(search) > 0:\n",
    "                similars.append((item[0], movie_name))\n",
    "\n",
    "        return similars[:top]\n",
    "\n",
    "    def recommend(self, user_id=4, top=10):\n",
    "        new_movie_ids = negative_dataset[user_id]\n",
    "\n",
    "        data = []\n",
    "        for movie_id in new_movie_ids:\n",
    "            bias_w = self.user_bias[user_id] if self.user_bias is not None else 0\n",
    "            bias_h = self.item_bias[movie_id] if self.item_bias is not None else 0\n",
    "\n",
    "            dot = np.dot(self.user_emb[user_id], self.item_emb[movie_id])\n",
    "            data.append((movie_id, dot + bias_w + bias_h))\n",
    "\n",
    "        data = list(sorted(data, key=lambda val: val[1], reverse=True))\n",
    "        recommendations = [movie_info[movie_info[\"movie_id\"] == x[0]][\"name\"].to_string() for x in data]\n",
    "        return recommendations[:top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline MF model: LightFM warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_recommender = Recommender(\n",
    "    baseline, \n",
    "    baseline.user_embeddings, \n",
    "    baseline.item_embeddings,\n",
    "    baseline.user_biases,\n",
    "    baseline.item_biases\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '0    Toy Story (1995)'),\n",
       " (588, '584    Aladdin (1992)'),\n",
       " (3114, '3045    Toy Story 2 (1999)'),\n",
       " (2355, \"2286    Bug's Life, A (1998)\"),\n",
       " (1197, '1179    Princess Bride, The (1987)'),\n",
       " (1265, '1245    Groundhog Day (1993)'),\n",
       " (364, '360    Lion King, The (1994)'),\n",
       " (595, '591    Beauty and the Beast (1991)'),\n",
       " (1073, '1058    Willy Wonka and the Chocolate Factory (1971)'),\n",
       " (2321, '2252    Pleasantville (1998)')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_recommender.similars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1178    Star Wars: Episode V - The Empire Strikes Back...',\n",
       " '847    Godfather, The (1972)',\n",
       " '585    Terminator 2: Judgment Day (1991)',\n",
       " '1192    Star Wars: Episode VI - Return of the Jedi (1983)',\n",
       " '1182    Aliens (1986)',\n",
       " '1203    Godfather: Part II, The (1974)',\n",
       " '108    Braveheart (1995)',\n",
       " '2502    Matrix, The (1999)',\n",
       " '453    Fugitive, The (1993)',\n",
       " '537    Blade Runner (1982)']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_recommender.recommend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
